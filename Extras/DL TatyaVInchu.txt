1. Linear regression by using Deep Neural network: Implement Boston housing price prediction problem by  inear regression using Deep Neural network. Use Boston House price prediction dataset.

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
df = pd.read_csv(r"/content/BostonHousingData.csv")
df
x = df.drop("MEDV", axis=1).values
y = df["MEDV"].values
x.shape
y.shape
 x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)
def shape():
    print("x_train Shape :",x_train.shape)
    print("x_test Shape :",x_test.shape)
    print("y_train shape :",y_train.shape)
    print("y_test shape :",y_test.shape)

shape()
mean=x_train.mean(axis=0)
std=x_train.std(axis=0)

x_train=(x_train-mean)/std
x_test=(x_test-mean)/std
x_train[0]
y_train[0]
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
model=Sequential()
model.add(Dense(128,activation='relu',input_shape=(x_train[0].shape)))
model.add(Dense(64,activation='relu'))
model.add(Dense(1,activation='linear'))
model.compile(optimizer='adam', loss='mse', metrics=['mae'])
model.summary()
model.fit(x_train, y_train, epochs=100, batch_size=1, verbose=1,validation_data=(x_test, y_test))
x_test[8]
test_input=[[-0.42101827, -0.50156705, -1.13081973, -0.25683275, -0.55572682, 0.19758953, 0.20684755, -0.34272202, -0.87422469, -0.84336666, -0.32505625, 0.41244772, -0.63500406]]

print("Actual Output :",y_test[8])
print("Predicted Output :",model.predict(test_input))
mse_nn,mae_nn=model.evaluate(x_test,y_test)

print('Mean squared error on test data :',mse_nn)
print('Mean absolute error on test data :',mae_nn)
from sklearn.metrics import r2_score

y_dl=model.predict(x_test)
r2=r2_score(y_test,y_dl)

print('R2 Score :',r2)

====================================================================================================


2. Classification using Deep neural network: Multiclass classification using Deep neural networks: Example : Use the OCR letter recognition dataset.

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
columns = ["lettr", "x-box", "y-box", "width", "height", "onpix", "x-bar","y-bar", "x2bar", "y2bar", "xybar", "x2ybr", "xy2br", "x-ege", "xegvy","y-ege", "yegvx"]
df = pd.read_csv(r"D:\Amit\PVG CLG\SEM 8\Practicals\letter-recognition.data", names=columns)
df
x = df.drop("lettr", axis=1).values
y = df["lettr"].values
x.shape
y.shape
np.unique(y)
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)
def shape():
    print("Train Shape :",x_train.shape)
    print("Test Shape :",x_test.shape)
    print("y_train shape :",y_train.shape)
    print("y_test shape :",y_test.shape)

shape()
 x_train[0]
 y_train[0]
class_names=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M','N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']
 x_test[10]
 y_test[10]
x_train = x_train/255
x_test = x_test/255
from sklearn.preprocessing import LabelEncoder

encoder = LabelEncoder()

y_train = encoder.fit_transform(y_train)
y_test = encoder.fit_transform(y_test)
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
model=Sequential()

model.add(Dense(512, activation='relu', input_shape=(16,)))
model.add(Dropout(0.2))

model.add(Dense(256, activation='relu'))
model.add(Dropout(0.2))

model.add(Dense(26, activation='softmax'))

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])
model.summary()
model.fit(x_train, y_train, epochs=50, batch_size=128, verbose=1,validation_data=(x_test, y_test))
 predictions = model.predict(x_test)
index=10

print(predictions[index])

final_value=np.argmax(predictions[index])

print("Actual label :",y_test[index])
print("Predicted label :",final_value)
print("Class (A-Z) :",class_names[final_value])
loss, accuracy = model.evaluate(x_test, y_test)

print("Loss :",loss)
print("Accuracy (Test Data) :",accuracy*100)

========================================================================================================
3. Classification using Deep neural network.Binary classification using Deep Neural Networks Example: Classify movie reviews into positive" reviews and "negative" reviews, just based on the text content of the reviews. Use the IMDB dataset.

from tensorflow.keras.datasets import imdb
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)
print("Train Shape :",x_train.shape)
print("Test Shape :",x_test.shape)
print("y_train shape :",y_train.shape)
print("y_test shape :",y_test.shape)
print(x_train[1])
print(y_train[1])
vocab=imdb.get_word_index()
print(vocab['the'])
class_names=['Negative', 'Positive']
reverse_index = dict([(value, key) for (key, value) in vocab.items()])
def decode(review):
    text=""
    for i in review:
        text=text+reverse_index[i]
        text=text+" "
    return text
 decode(x_train[1])
def showlen():
    print("Length of first training sample: ",len(x_train[0]))
    print("Length of second training sample: ",len(x_train[1]))
    print("Length of first test sample: ",len(x_test[0]))
    print("Length of second test sample: ",len(x_test[1]))

showlen()
from tensorflow.keras.preprocessing.sequence import pad_sequences

x_train=pad_sequences(x_train, value=vocab['the'], padding='post', maxlen=256)
x_test=pad_sequences(x_test, value=vocab['the'], padding='post', maxlen=256)
showlen()
decode(x_train[1])
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D
model=Sequential()

model.add(Embedding(10000,16))
model.add(GlobalAveragePooling1D())

model.add(Dense(16,activation='relu'))
model.add(Dense(1,activation='sigmoid'))

model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])

model.summary()
 model.fit(x_train, y_train, epochs=4, batch_size=128, verbose=1,validation_data=(x_test, y_test))
 x_test[10]
 y_test[10]
import numpy as np

predicted_value=model.predict(np.expand_dims(x_test[10], 0))

print(predicted_value)

if predicted_value>0.5:
    final_value=1
else:
    final_value=0

print(final_value)
print(class_names[final_value])
loss, accuracy = model.evaluate(x_test, y_test)

print("Loss :",loss)
print("Accuracy (Test Data) :",accuracy*100)

========================================================================================

4. Convolutional neural network (CNN). Use any dataset of plant disease and design and design a plant disease detection system using CNN.

from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
train_dir = r'C:\Users\mohit\Downloads\Dataset\New Plant Diseases Dataset(Augmented)\train'
val_dir = r'C:\Users\mohit\Downloads\Dataset\New Plant Diseases Dataset(Augmented)\valid'
img_size = 224
batch_size = 8
train_datagen = ImageDataGenerator(rescale=1./255)
train_generator = train_datagen.flow_from_directory(train_dir, target_size=(img_size, img_size), batch_size=batch_size, class_mode='categorical')
val_datagen = ImageDataGenerator(rescale=1./255)
val_generator = val_datagen.flow_from_directory(val_dir, target_size=(img_size, img_size), batch_size=batch_size, class_mode='categorical')
list(train_generator.class_indices)
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
model = Sequential()

model.add((Conv2D(32, (3,3), activation='relu', input_shape=(img_size, img_size, 3))))

model.add(BatchNormalization())
model.add((MaxPooling2D(2,2)))

model.add((Conv2D(64, (3,3), activation='relu')))

model.add(BatchNormalization())
model.add((MaxPooling2D(2,2)))

model.add((Conv2D(64, (3,3), activation='relu')))

model.add(BatchNormalization())
model.add((MaxPooling2D(2,2)))

model.add((Conv2D(128, (3,3), activation='relu')))

model.add(BatchNormalization())
model.add((MaxPooling2D(2,2)))

model.add((Flatten()))

model.add((Dense(128, activation='relu')))
model.add((Dropout(0.2)))

model.add((Dense(64, activation='relu')))
model.add((Dense(train_generator.num_classes, activation='softmax')))

model.summary()
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(train_generator, epochs=15, validation_data=val_generator)
loss, accuracy = model.evaluate(val_generator)
print("Loss :",loss)
print("Accuracy (Test Data) :",accuracy*100)
import numpy as np

img_path =r'C:\Users\mohit\Downloads\Dataset\New Plant Diseases Dataset(Augmented)\valid\Tomato___Early_blight\5b86ab6a-3823-4886-85fd-02190898563c___RS_Erly.B 8452.JPG'

img = load_img(img_path, target_size=(224, 224))
img_array = img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)
img_array /= 255.
prediction = model.predict(img_array)
class_names=['Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___healthy']
predicted_class = np.argmax(prediction)
print(prediction)
print(predicted_class)
print('Predicted class:', class_names[predicted_class])

=======================================================================================================


5. Convolutional neural network (CNN).Use MNIST Fashion Dataset and create a classifier to classify fashion clothing into categories.

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
class_names=['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankleboot']
df1 = pd.read_csv(r'C:\Users\mohit\Downloads\Dataset\fashion-mnist_train.csv')
df1
x_train = df1.drop("label", axis=1).values
y_train = df1["label"].values
print("x_train shape: ",x_train.shape)
print("y_train shape: ",y_train.shape)
np.unique(y_train)
df2 = pd.read_csv(r'C:\Users\mohit\Downloads\Dataset\fashion-mnist_test.csv')
df2
x_test = df2.drop("label", axis=1).values
y_test = df2["label"].values
print("x_test shape: ",x_test.shape)
print("y_test shape: ",y_test.shape)
x_train = x_train.reshape(60000, 28, 28)
x_test = x_test.reshape(10000, 28, 28)
print(x_train[0])
y_train[0]
plt.imshow(x_train[0])
x_test[10]
y_test[10]
plt.imshow(x_test[10])
x_train = x_train/255
x_test = x_test/255
x_train = x_train.reshape(60000, 28, 28, 1)
x_test = x_test.reshape(10000, 28, 28, 1)
print("Train Shape :",x_train.shape)
print("Test Shape :",x_test.shape)
print("y_train shape :",y_train.shape)
print("y_test shape :",y_test.shape)
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten
model=Sequential()

model.add(Conv2D(64, (3,3), activation='relu', input_shape=(28,28,1)))
model.add(MaxPooling2D((2,2)))

model.add(Conv2D(64, (3,3), activation='relu'))
model.add(MaxPooling2D((2,2)))

model.add(Flatten())

model.add(Dense(128,activation='relu'))
model.add(Dense(10,activation='softmax'))

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])

model.summary()
model.fit(x_train, y_train, epochs=3, verbose=1, validation_data=(x_test,y_test))
predictions = model.predict(x_test)
import numpy as np

index=10

print(predictions[index])

final_value=np.argmax(predictions[index])

print("Actual label :",y_test[index])
print("Predicted label :",final_value)
print("Class :",class_names[final_value])
plt.imshow(x_test[10])
loss, accuracy = model.evaluate(x_test, y_test)

print("Loss :",loss)
print("Accuracy (Test Data) :",accuracy*100)

==========================================================================================